{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import cached_property, cache\n",
    "from typing import Tuple, List\n",
    "from pandas import DataFrame, read_parquet\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import zarr\n",
    "from tifffile import imread, TiffFile\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df_path: str):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.df = read_parquet(df_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(    \n",
    "        self, index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"General getitem function for sbrnet-related datasets. require the stack of lightfield views,\n",
    "          and the refocused volume as inputs. and the the ground truth target.\n",
    "\n",
    "        Args:\n",
    "            index (int): index of the data. the input measurement data is stored in the format of meas_{index}.tiff,\n",
    "            and the output is stored in the format of gt_vol_{index}.tiff. yours may change, so adjust this function accordingly.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: your data in torch tensor form normalized to [0,1] with 32bit float.\n",
    "        \"\"\"\n",
    "\n",
    "        image = imread(self.df[\"image_path\"].iloc[index]).astype(np.float32) / 0xFFFF\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        label = imread(self.df[\"label_path\"].iloc[index]).astype(np.float32) / 0xFFFF\n",
    "        label = torch.from_numpy(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class ZarrData:\n",
    "    def __init__(self, df: DataFrame, datatype: str):\n",
    "        self.df = df\n",
    "        self.datatype = datatype\n",
    "\n",
    "    # NOTE: ensure cache is larger than number of items\n",
    "    @cache\n",
    "    def __getitem__(self, index: int):\n",
    "        path = self.df[self.datatype + \"_path\"].iloc[index]\n",
    "        with TiffFile(path) as img:\n",
    "            return zarr.open(img.aszarr())\n",
    "\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, df_path: str, patch_size: int):\n",
    "        \"\"\"Dataset class for patch data (cropping).\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset): the train split dataset after torch.utils.data.randomsplit for valid and train\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.df = read_parquet(df_path)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    @cached_property\n",
    "    def image(self) -> ZarrData:\n",
    "        return ZarrData(self.df, \"image\")\n",
    "\n",
    "    @cached_property\n",
    "    def label(self) -> ZarrData:\n",
    "        return ZarrData(self.df, \"label\")\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"retrieves a random patch of the data with size patch_size\n",
    "\n",
    "        Args:\n",
    "            idx (int): index of the data.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: patch of the data with size patch_size.\n",
    "\n",
    "            Note: One may realize that for RFV, we may crop out some peripheral information that's correlated\n",
    "            with the GT, but we neglect this correlation as the axial shearing from the off-axis microlenses\n",
    "            is not significant.\n",
    "        \"\"\"\n",
    "        # Recipe for fast dataloading with zarr courtesy of Mitchell Gilmore mgilm0re@bu.edu\n",
    "        image = self.image[idx]\n",
    "        label = self.label[idx]\n",
    "\n",
    "        # uniformly sample a patch\n",
    "        row_start = torch.randint(0, image.shape[-2] - self.patch_size, (1,))\n",
    "        col_start = torch.randint(0, image.shape[-1] - self.patch_size, (1,))\n",
    "\n",
    "        row_slice = slice(row_start, row_start + self.patch_size)\n",
    "        col_slice = slice(col_start, col_start + self.patch_size)\n",
    "\n",
    "        image = torch.from_numpy(\n",
    "            image[row_slice, col_slice].astype(np.float32) / 255\n",
    "        )\n",
    "        label = torch.from_numpy(label[row_slice, col_slice].astype(np.float32) / 255)\n",
    "        \n",
    "        return image[None,...], label[None,...]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import read_parquet\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import logging\n",
    "from typing import Tuple\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Module,\n",
    "        config: dict,\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        self.epochs = config[\"epochs\"]\n",
    "        self.model_dir = config[\"model_dir\"]\n",
    "        self.lowest_val_loss = float(\"inf\")\n",
    "        self.training_losses = []\n",
    "        self.validation_losses = []\n",
    "        self.random_seed = config.get(\"random_seed\", None)\n",
    "        self.use_amp = config.get(\"use_amp\", False)\n",
    "        self.optimizer_name = config.get(\"optimizer\", \"adam\")\n",
    "        self.lr_scheduler_name = config.get(\"lr_scheduler\", \"cosine_annealing\")\n",
    "        self.criterion_name = config.get(\"loss_criterion\", \"bce_with_logits\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "\n",
    "        self.logger.debug(f\"Using device: {self.device}\")\n",
    "        self.scaler = (\n",
    "            GradScaler() if self.use_amp else None\n",
    "        )  # Initialize the scaler if using AMP\n",
    "\n",
    "        # Initialize the loss criterion based on the configuration\n",
    "        if self.criterion_name == \"bce_with_logits\":\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "        elif self.criterion_name == \"mse\":\n",
    "            self.criterion = nn.MSELoss()\n",
    "        elif self.criterion_name == \"mae\":\n",
    "            self.criterion = nn.L1Loss()\n",
    "        else:\n",
    "            print(\n",
    "                f\"Unknown loss criterion: {self.criterion_name}. Using BCEWithLogitsLoss.\"\n",
    "            )\n",
    "        self.train_data_loader, self.val_data_loader = self._get_dataloaders()\n",
    "\n",
    "    def _get_dataloaders(self) -> Tuple[DataLoader, DataLoader]:\n",
    "        def split_dataset(dataset, split_ratio):\n",
    "            dataset_size = len(dataset)\n",
    "            train_size = int(split_ratio * dataset_size)\n",
    "            val_size = dataset_size - train_size\n",
    "            train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "                dataset, [train_size, val_size]\n",
    "            )\n",
    "            return train_dataset, val_dataset\n",
    "\n",
    "        complete_dataset: Dataset = CustomDataset(self.config[\"dataset_pq\"])\n",
    "        split_ratio = self.config[\"train_split\"]\n",
    "        train_dataset, val_dataset = split_dataset(complete_dataset, split_ratio)\n",
    "\n",
    "        # only train_dataset is a PatchDataset. val_dataset is full sized images.\n",
    "        train_dataset = PatchDataset(\n",
    "            dataset=train_dataset,\n",
    "            df_path=self.config[\"dataset_pq\"],\n",
    "            patch_size=self.config[\"patch_size\"],\n",
    "        )\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset, self.config.get(\"batch_size\"), shuffle=True\n",
    "        )\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset, self.config[\"batch_size\"], shuffle=True\n",
    "        )\n",
    "\n",
    "        return train_dataloader, val_dataloader\n",
    "\n",
    "    def _set_random_seed(self):\n",
    "        if self.random_seed is not None:\n",
    "            torch.manual_seed(self.random_seed)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.manual_seed_all(self.random_seed)\n",
    "\n",
    "    def _initialize_optimizer(self):\n",
    "        if self.optimizer_name == \"adam\":\n",
    "            optimizer = optim.Adam(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "            )\n",
    "        elif self.optimizer_name == \"sgd\":\n",
    "            optimizer = optim.SGD(\n",
    "                self.model.parameters(), lr=self.learning_rate, momentum=0.9\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Unknown optimizer: {self.optimizer_name}. Using Adam.\")\n",
    "            optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def _initialize_lr_scheduler(self, optimizer):\n",
    "        if self.lr_scheduler_name == \"cosine_annealing\":\n",
    "            scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=self.config[\"cosine_annealing_T_max\"]\n",
    "            )\n",
    "        elif self.lr_scheduler_name == \"step_lr\":\n",
    "            # StepLR scheduler\n",
    "            step_size = self.config.get(\"step_lr_step_size\", 10)\n",
    "            gamma = self.config.get(\"step_lr_gamma\", 0.5)\n",
    "            scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "        elif self.lr_scheduler_name == \"plateau\":\n",
    "            # Plateau scheduler\n",
    "            patience = self.config.get(\"plateau_patience\", 10)\n",
    "            factor = self.config.get(\"plateau_factor\", 0.5)\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, patience=patience, factor=factor, verbose=True\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"Unknown LR scheduler: {self.lr_scheduler_name}. Using Cosine Annealing.\"\n",
    "            )\n",
    "            scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
    "        return scheduler\n",
    "\n",
    "    def train(self):\n",
    "        model_name = f\"sbrnet_{timestamp}.pt\"\n",
    "        self.model.to(self.device)\n",
    "        self._set_random_seed()\n",
    "\n",
    "        optimizer = self._initialize_optimizer()\n",
    "        scheduler = self._initialize_lr_scheduler(optimizer)\n",
    "        start_time = time.time()\n",
    "\n",
    "        if self.use_amp:\n",
    "            print(\"Using mixed-precision training with AMP.\")\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            for image, label in self.train_data_loader:\n",
    "                image, label = (\n",
    "                    image.to(self.device),\n",
    "                    label.to(self.device),\n",
    "                )\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        output = self.model(image)\n",
    "                        loss = self.criterion(output, label)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    output = self.model(image)\n",
    "                    loss = self.criterion(output, label)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                self.logger.debug(f\"Epoch [{epoch + 1}/{self.epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = total_loss / len(self.train_data_loader)\n",
    "            self.training_losses.append(avg_train_loss)\n",
    "            self.logger.info(\n",
    "                f\"Epoch [{epoch + 1}/{self.epochs}], Train Loss: {avg_train_loss}\"\n",
    "            )\n",
    "\n",
    "            val_loss = self.validate()\n",
    "            self.validation_losses.append(val_loss)\n",
    "            self.logger.info(\n",
    "                f\"Epoch [{epoch + 1}/{self.epochs}], Validation Loss: {val_loss}\"\n",
    "            )\n",
    "\n",
    "            if self.lr_scheduler_name == \"plateau\":\n",
    "                scheduler.step(\n",
    "                    val_loss\n",
    "                )  # For Plateau scheduler, pass validation loss as an argument\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "            if val_loss < self.lowest_val_loss:\n",
    "                self.lowest_val_loss = val_loss\n",
    "                save_state = {\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"model_state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"training_losses\": self.training_losses,\n",
    "                    \"validation_losses\": self.validation_losses,\n",
    "                    \"time_elapsed\": time.time() - start_time,\n",
    "                }\n",
    "\n",
    "                save_state.update(self.config)\n",
    "                model_save_path = os.path.join(self.model_dir, model_name)\n",
    "                torch.save(save_state, model_save_path)\n",
    "                self.logger.info(\"Model saved at epoch {}\".format(epoch + 1))\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for image, label in self.val_data_loader:\n",
    "                image, label = (\n",
    "                    image.to(self.device),\n",
    "                    label.to(self.device),\n",
    "                )\n",
    "                output = self.model(image)\n",
    "                loss = self.criterion(output, label)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(self.val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1706, 1510])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CustomDataset(\"/ad/eng/research/eng_research_cisl/jalido/kaggle/vessel_segmentatio/train/train_df.parquet\")\n",
    "patch_dataset = PatchDataset(dataset, \"/ad/eng/research/eng_research_cisl/jalido/kaggle/vessel_segmentatio/train/train_df.parquet\", 224)\n",
    "\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /usr3/bustaff/jalido/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Using mixed-precision training with AMP.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc1/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model, args_dict)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc1/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarting training...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bscc1/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc1/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining complete.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bscc1/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=162'>163</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(image)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bscc1/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=163'>164</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(output, label)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bscc1/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=164'>165</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bscc1/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=165'>166</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mstep(optimizer)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bscc1/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/src/submissions/scratch.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=166'>167</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# One-time script to generate dataframe parquet to map index to files\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "BASE_DIR = os.path.join(\"/ad/eng/research/eng_research_cisl/jalido/kaggle/vessel_segmentatio/\")\n",
    "train_dir_path = os.path.join(BASE_DIR, \"train\")\n",
    "\n",
    "folders = os.listdir(train_dir_path)\n",
    "\n",
    "subfolders = [\"images\", \"labels\"]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# for folder in folders: \n",
    "#     if folder == \"kidney_3_dense\":\n",
    "#         # This folder only contains labels\n",
    "#         continue\n",
    "\n",
    "#     for subfolder in subfolders:\n",
    "#         subfolder_path = os.path.join(train_dir_path, folder, subfolder)\n",
    "#         files = os.listdir(subfolder_path)\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(subfolder_path, file)\n",
    "#             if subfolder == \"images\":\n",
    "#                 _df = pd.DataFrame.from_dict({\"image_path\": [file_path], \"label_path\": [None]})\n",
    "#                 df = pd.concat([_df, df], ignore_index=True)\n",
    "#             else:\n",
    "#                 image_file_path = os.path.join(os.path.dirname(os.path.dirname(file_path)), \"images\", file)\n",
    "#                 df.loc[df[\"image_path\"] == image_file_path, \"label_path\"] = file_path\n",
    "\n",
    "# df.to_parquet(os.path.join(train_dir_path, \"train_df.parquet\"))\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "args_dict = {\n",
    "    \"dataset_pq\": os.path.join(train_dir_path, \"train_df.parquet\"),\n",
    "    \"model_dir\": os.path.join(BASE_DIR, \"model_dir\", f\"{timestamp}.pt\"),\n",
    "    \"train_split\": 0.8,\n",
    "    \"batch_size\": 12,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 20000,\n",
    "    \"weight_init\": \"kaiming_normal\",\n",
    "    \"random_seed\": 42,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"criterion_name\": \"bce_with_logits\",\n",
    "    \"use_amp\": True,\n",
    "    \"lr_scheduler\": \"cosine_annealing\",\n",
    "    \"cosine_annealing_T_max\": 30,\n",
    "    \"patch_size\": 224,\n",
    "}\n",
    "\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "                in_channels=1, out_channels=1, init_features=32, pretrained=False)\n",
    "\n",
    "trainer = Trainer(model, args_dict)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
