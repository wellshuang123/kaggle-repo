{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import cached_property, cache\n",
    "from typing import Tuple, List\n",
    "from pandas import DataFrame, read_parquet\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import zarr\n",
    "from tifffile import imread, TiffFile\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df_path: str):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.df = read_parquet(df_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(    \n",
    "        self, index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"General getitem function for sbrnet-related datasets. require the stack of lightfield views,\n",
    "          and the refocused volume as inputs. and the the ground truth target.\n",
    "\n",
    "        Args:\n",
    "            index (int): index of the data. the input measurement data is stored in the format of meas_{index}.tiff,\n",
    "            and the output is stored in the format of gt_vol_{index}.tiff. yours may change, so adjust this function accordingly.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: your data in torch tensor form normalized to [0,1] with 32bit float.\n",
    "        \"\"\"\n",
    "\n",
    "        image = imread(self.df[\"image_path\"].iloc[index]).astype(np.float32) / 0xFFFF\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        label = imread(self.df[\"label_path\"].iloc[index]).astype(np.float32) / 0xFFFF\n",
    "        label = torch.from_numpy(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class ZarrData:\n",
    "    def __init__(self, df: DataFrame, datatype: str):\n",
    "        self.df = df\n",
    "        self.datatype = datatype\n",
    "\n",
    "    # NOTE: ensure cache is larger than number of items\n",
    "    @cache\n",
    "    def __getitem__(self, index: int):\n",
    "        path = self.df[self.datatype + \"_path\"].iloc[index]\n",
    "        with TiffFile(path) as img:\n",
    "            return zarr.open(img.aszarr())\n",
    "\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, df_path: str, patch_size: int):\n",
    "        \"\"\"Dataset class for patch data (cropping).\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset): the train split dataset after torch.utils.data.randomsplit for valid and train\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.df = read_parquet(df_path)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    @cached_property\n",
    "    def image(self) -> ZarrData:\n",
    "        return ZarrData(self.df, \"image\")\n",
    "\n",
    "    @cached_property\n",
    "    def label(self) -> ZarrData:\n",
    "        return ZarrData(self.df, \"label\")\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"retrieves a random patch of the data with size patch_size\n",
    "\n",
    "        Args:\n",
    "            idx (int): index of the data.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: patch of the data with size patch_size.\n",
    "\n",
    "            Note: One may realize that for RFV, we may crop out some peripheral information that's correlated\n",
    "            with the GT, but we neglect this correlation as the axial shearing from the off-axis microlenses\n",
    "            is not significant.\n",
    "        \"\"\"\n",
    "        # Recipe for fast dataloading with zarr courtesy of Mitchell Gilmore mgilm0re@bu.edu\n",
    "        image = self.image[idx]\n",
    "        label = self.label[idx]\n",
    "\n",
    "        # uniformly sample a patch\n",
    "        row_start = torch.randint(0, image.shape[-2] - self.patch_size, (1,))\n",
    "        col_start = torch.randint(0, image.shape[-1] - self.patch_size, (1,))\n",
    "\n",
    "        row_slice = slice(row_start, row_start + self.patch_size)\n",
    "        col_slice = slice(col_start, col_start + self.patch_size)\n",
    "\n",
    "        image = torch.from_numpy(\n",
    "            image[row_slice, col_slice].astype(np.float32) / 255\n",
    "        )\n",
    "        label = torch.from_numpy(label[row_slice, col_slice].astype(np.float32) / 255)\n",
    "        \n",
    "        return image[None,...], label[None,...]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import read_parquet\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import logging\n",
    "from typing import Tuple\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Module,\n",
    "        config: dict,\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        self.epochs = config[\"epochs\"]\n",
    "        self.model_dir = config[\"model_dir\"]\n",
    "        self.lowest_val_loss = float(\"inf\")\n",
    "        self.training_losses = []\n",
    "        self.validation_losses = []\n",
    "        self.random_seed = config.get(\"random_seed\", None)\n",
    "        self.use_amp = config.get(\"use_amp\", False)\n",
    "        self.optimizer_name = config.get(\"optimizer\", \"adam\")\n",
    "        self.lr_scheduler_name = config.get(\"lr_scheduler\", \"cosine_annealing\")\n",
    "        self.criterion_name = config.get(\"loss_criterion\", \"bce_with_logits\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        print(\"DEVICE: \", self.device)\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "\n",
    "        self.logger.debug(f\"Using device: {self.device}\")\n",
    "        self.scaler = (\n",
    "            GradScaler() if self.use_amp else None\n",
    "        )  # Initialize the scaler if using AMP\n",
    "\n",
    "        # Initialize the loss criterion based on the configuration\n",
    "        if self.criterion_name == \"bce_with_logits\":\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "        elif self.criterion_name == \"mse\":\n",
    "            self.criterion = nn.MSELoss()\n",
    "        elif self.criterion_name == \"mae\":\n",
    "            self.criterion = nn.L1Loss()\n",
    "        else:\n",
    "            print(\n",
    "                f\"Unknown loss criterion: {self.criterion_name}. Using BCEWithLogitsLoss.\"\n",
    "            )\n",
    "        self.train_data_loader, self.val_data_loader = self._get_dataloaders()\n",
    "\n",
    "    def _get_dataloaders(self) -> Tuple[DataLoader, DataLoader]:\n",
    "        def split_dataset(dataset, split_ratio):\n",
    "            dataset_size = len(dataset)\n",
    "            train_size = int(split_ratio * dataset_size)\n",
    "            val_size = dataset_size - train_size\n",
    "            train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "                dataset, [train_size, val_size]\n",
    "            )\n",
    "            return train_dataset, val_dataset\n",
    "\n",
    "        complete_dataset: Dataset = CustomDataset(self.config[\"dataset_pq\"])\n",
    "        split_ratio = self.config[\"train_split\"]\n",
    "        train_dataset, val_dataset = split_dataset(complete_dataset, split_ratio)\n",
    "\n",
    "        # only train_dataset is a PatchDataset. val_dataset is full sized images.\n",
    "        train_dataset = PatchDataset(\n",
    "            dataset=train_dataset,\n",
    "            df_path=self.config[\"dataset_pq\"],\n",
    "            patch_size=self.config[\"patch_size\"],\n",
    "        )\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset, self.config.get(\"batch_size\"), shuffle=True\n",
    "        )\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset, self.config[\"batch_size\"], shuffle=True\n",
    "        )\n",
    "\n",
    "        return train_dataloader, val_dataloader\n",
    "\n",
    "    def _set_random_seed(self):\n",
    "        if self.random_seed is not None:\n",
    "            torch.manual_seed(self.random_seed)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.manual_seed_all(self.random_seed)\n",
    "\n",
    "    def _initialize_optimizer(self):\n",
    "        if self.optimizer_name == \"adam\":\n",
    "            optimizer = optim.Adam(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "            )\n",
    "        elif self.optimizer_name == \"sgd\":\n",
    "            optimizer = optim.SGD(\n",
    "                self.model.parameters(), lr=self.learning_rate, momentum=0.9\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Unknown optimizer: {self.optimizer_name}. Using Adam.\")\n",
    "            optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def _initialize_lr_scheduler(self, optimizer):\n",
    "        if self.lr_scheduler_name == \"cosine_annealing\":\n",
    "            scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=self.config[\"cosine_annealing_T_max\"]\n",
    "            )\n",
    "        elif self.lr_scheduler_name == \"step_lr\":\n",
    "            # StepLR scheduler\n",
    "            step_size = self.config.get(\"step_lr_step_size\", 10)\n",
    "            gamma = self.config.get(\"step_lr_gamma\", 0.5)\n",
    "            scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "        elif self.lr_scheduler_name == \"plateau\":\n",
    "            # Plateau scheduler\n",
    "            patience = self.config.get(\"plateau_patience\", 10)\n",
    "            factor = self.config.get(\"plateau_factor\", 0.5)\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, patience=patience, factor=factor, verbose=True\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"Unknown LR scheduler: {self.lr_scheduler_name}. Using Cosine Annealing.\"\n",
    "            )\n",
    "            scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
    "        return scheduler\n",
    "\n",
    "    def train(self):\n",
    "        model_name = f\"sbrnet_{timestamp}.pt\"\n",
    "        self.model.to(self.device)\n",
    "        self._set_random_seed()\n",
    "\n",
    "        optimizer = self._initialize_optimizer()\n",
    "        scheduler = self._initialize_lr_scheduler(optimizer)\n",
    "        start_time = time.time()\n",
    "\n",
    "        if self.use_amp:\n",
    "            print(\"Using mixed-precision training with AMP.\")\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            for image, label in self.train_data_loader:\n",
    "                # print(image.shape, label.shape)\n",
    "                image, label = (\n",
    "                    image.to(self.device),\n",
    "                    label.to(self.device),\n",
    "                )\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        output = self.model(image)\n",
    "                        loss = self.criterion(output, label)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    output = self.model(image)\n",
    "                    loss = self.criterion(output, label)\n",
    "                    print(loss)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                self.logger.debug(f\"Epoch [{epoch + 1}/{self.epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = total_loss / len(self.train_data_loader)\n",
    "            self.training_losses.append(avg_train_loss)\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{self.epochs}], Train Loss: {avg_train_loss}\"\n",
    "            )\n",
    "\n",
    "            val_loss = self.validate()\n",
    "            self.validation_losses.append(val_loss)\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{self.epochs}], Validation Loss: {val_loss}\"\n",
    "            )\n",
    "\n",
    "            if self.lr_scheduler_name == \"plateau\":\n",
    "                scheduler.step(\n",
    "                    val_loss\n",
    "                )  # For Plateau scheduler, pass validation loss as an argument\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "            if val_loss < self.lowest_val_loss:\n",
    "                self.lowest_val_loss = val_loss\n",
    "                save_state = {\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"model_state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"training_losses\": self.training_losses,\n",
    "                    \"validation_losses\": self.validation_losses,\n",
    "                    \"time_elapsed\": time.time() - start_time,\n",
    "                }\n",
    "\n",
    "                save_state.update(self.config)\n",
    "                model_save_path = os.path.join(self.model_dir, model_name)\n",
    "                torch.save(save_state, model_save_path)\n",
    "                print(\"Model saved at epoch {}\".format(epoch + 1))\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for image, label in self.val_data_loader:\n",
    "                image, label = (\n",
    "                    image.to(self.device),\n",
    "                    label.to(self.device),\n",
    "                )\n",
    "                output = self.model(image)\n",
    "                loss = self.criterion(output, label)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(self.val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1706, 1510])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CustomDataset(\"/ad/eng/research/eng_research_cisl/jalido/kaggle/vessel_segmentatio/train/train_df.parquet\")\n",
    "patch_dataset = PatchDataset(dataset, \"/ad/eng/research/eng_research_cisl/jalido/kaggle/vessel_segmentatio/train/train_df.parquet\", 224)\n",
    "\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /usr3/bustaff/jalido/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:  cuda\n",
      "Starting training...\n",
      "tensor(0.9329, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.9084, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.8822, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.8410, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.8273, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.8356, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.8106, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7782, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7755, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7582, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7472, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7370, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7282, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7213, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7202, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7115, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7082, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7056, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7037, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7003, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6992, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6985, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6990, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6975, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_27360/1685534353.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ipykernel_27360/375858428.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0;31m# print(image.shape, label.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 image, label = (\n\u001b[1;32m    156\u001b[0m                     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IterableDataset_len_called\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ipykernel_27360/2619236796.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mrow_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mcol_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         image = torch.from_numpy(\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/zarr/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, selection)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpure_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpop_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_pure_fancy_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpure_selection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_pure_orthogonal_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpure_selection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_orthogonal_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpure_selection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_basic_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpure_selection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/zarr/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;31m# setup indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrthogonalIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/zarr/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, indexer, out, fields)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m             \u001b[0;31m# allow storage to get multiple items at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0mlchunk_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlchunk_selection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlout_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m             self._chunk_getitems(\n\u001b[0m\u001b[1;32m   1389\u001b[0m                 \u001b[0mlchunk_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m                 \u001b[0mlchunk_selection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/zarr/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, lchunk_coords, lchunk_selection, out, lout_selection, drop_axes, fields)\u001b[0m\n\u001b[1;32m   2220\u001b[0m             \u001b[0mpartial_read_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2221\u001b[0m             \u001b[0mcontexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m                 \u001b[0mcontexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstantMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m             \u001b[0mcdatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mckey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_select\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_select\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlchunk_selection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlout_selection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mckey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcdatas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/zarr/_storage/store.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, keys, contexts)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mimplementation\u001b[0m \u001b[0muses\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mread\u001b[0m \u001b[0meach\u001b[0m \u001b[0mkey\u001b[0m \u001b[0msequentially\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mignores\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOverwrite\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mto\u001b[0m \u001b[0mimplement\u001b[0m \u001b[0mconcurrent\u001b[0m \u001b[0mreads\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmultiple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0mto\u001b[0m \u001b[0mutilize\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \"\"\"\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/zarr/_storage/store.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     def getitems(\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     ) -> Mapping[str, Any]:\n\u001b[1;32m    163\u001b[0m         \"\"\"Retrieve data from multiple keys.\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/zarr/storage.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutable_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m  12336\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.zarray'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.zgroup'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12338\u001b[0m             \u001b[0;31m# catch '.zarray' and 'attribute/.zarray'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12339\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 12340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m  13046\u001b[0m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13047\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13049\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbytecount\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 13050\u001b[0;31m         \u001b[0mchunk_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytecount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  13051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13052\u001b[0m         \u001b[0mdecodeargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'_fullsize'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjpegtables\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fh, offset, bytecount, whence)\u001b[0m\n\u001b[1;32m  14970\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14971\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14972\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14973\u001b[0m             \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 14974\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytecount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  14975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14976\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14977\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projectnb/tianlabdl/jalido/segmentation/sennet-hoa/.direnv/lib/python3.11/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m  14393\u001b[0m         \"\"\"\n\u001b[1;32m  14394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14395\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14396\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 14397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# One-time script to generate dataframe parquet to map index to files\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "BASE_DIR = os.path.join(\"/ad/eng/research/eng_research_cisl/jalido/kaggle/vessel_segmentatio/\")\n",
    "train_dir_path = os.path.join(BASE_DIR, \"train\")\n",
    "\n",
    "folders = os.listdir(train_dir_path)\n",
    "\n",
    "subfolders = [\"images\", \"labels\"]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# for folder in folders: \n",
    "#     if folder == \"kidney_3_dense\":\n",
    "#         # This folder only contains labels\n",
    "#         continue\n",
    "\n",
    "#     for subfolder in subfolders:\n",
    "#         subfolder_path = os.path.join(train_dir_path, folder, subfolder)\n",
    "#         files = os.listdir(subfolder_path)\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(subfolder_path, file)\n",
    "#             if subfolder == \"images\":\n",
    "#                 _df = pd.DataFrame.from_dict({\"image_path\": [file_path], \"label_path\": [None]})\n",
    "#                 df = pd.concat([_df, df], ignore_index=True)\n",
    "#             else:\n",
    "#                 image_file_path = os.path.join(os.path.dirname(os.path.dirname(file_path)), \"images\", file)\n",
    "#                 df.loc[df[\"image_path\"] == image_file_path, \"label_path\"] = file_path\n",
    "\n",
    "# df.to_parquet(os.path.join(train_dir_path, \"train_df.parquet\"))\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"NVIDIA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "args_dict = {\n",
    "    \"dataset_pq\": os.path.join(train_dir_path, \"train_df.parquet\"),\n",
    "    \"model_dir\": os.path.join(BASE_DIR, \"model_dir\", f\"{timestamp}.pt\"),\n",
    "    \"train_split\": 0.8,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 20000,\n",
    "    \"weight_init\": \"kaiming_normal\",\n",
    "    \"random_seed\": 42,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"criterion_name\": \"bce_with_logits\",\n",
    "    \"use_amp\": False,\n",
    "    \"lr_scheduler\": \"cosine_annealing\",\n",
    "    \"cosine_annealing_T_max\": 30,\n",
    "    \"patch_size\": 224,\n",
    "}\n",
    "\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "                in_channels=1, out_channels=1, init_features=32, pretrained=False)\n",
    "\n",
    "trainer = Trainer(model, args_dict)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
